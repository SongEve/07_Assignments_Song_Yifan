{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4fc743ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b17bfb",
   "metadata": {},
   "source": [
    "### My AutoGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e3cf73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input\n",
    "\n",
    "batch_size = 1\n",
    "hidden_node = 21 # 2d+1 \n",
    "input_data = 10 #d=10\n",
    "output_data = 1\n",
    "hidden_layer = 10\n",
    "learning_rate = 1e-6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "25f525a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define x, y\n",
    "runif = torch.distributions.Uniform(0,1)\n",
    "x = runif.sample((batch_size,input_data))\n",
    "y = x.pow(2).sum()/2\n",
    "\n",
    "#Weight & Bias\n",
    "w1 = torch.randn(input_data, hidden_node) #1\n",
    "b1 = torch.randn(1, hidden_node)\n",
    "w_list=[w1]\n",
    "b_list=[b1]\n",
    "for i in range(9):\n",
    "    w_list.append(torch.randn(hidden_node, hidden_node)) #1+9\n",
    "    b_list.append(torch.randn(1, hidden_node))\n",
    "w11 = torch.randn(hidden_node, output_data) \n",
    "b11 = torch.randn(1, output_data)\n",
    "w_list.append(w11)\n",
    "b_list.append(b11)\n",
    "\n",
    "\n",
    "#Forward-propagation\n",
    "h_list=[F.relu(torch.matmul(x, w_list[0])+b_list[0],)]#1 0\n",
    "for i in range(9):\n",
    "    h_list.append(F.relu(torch.matmul(h_list[i], w_list[i+1])+b_list[i+1])) #9 0-8\n",
    "y_pred = F.relu(torch.matmul(h_list[9], w_list[10])+b_list[10])\n",
    "\n",
    "#Loss Function\n",
    "loss = (y_pred-y).pow(2).sum()\n",
    "\n",
    "#Back-propagation\n",
    "grad_y_pred = 2*(y_pred - y)\n",
    "w_grad = [0]*11\n",
    "b_grad = [0]*11\n",
    "\n",
    "for i in range(11):\n",
    "    if i == 0:\n",
    "        b_grad[10 - i] = grad_y_pred\n",
    "        w_grad[10 - i] = (b_grad[10-i] * h_list[9-i].T )\n",
    "    elif i == 10:\n",
    "        b_grad[10 - i] = torch.mm(b_grad[11-i],w_list[11 - i].T)\n",
    "        b_grad[10 - i][h_list[10 - i]<=0] = 0\n",
    "        w_grad[10 - i] = torch.mm(x.T,b_grad[10-i])\n",
    "    else:\n",
    "        b_grad[10 - i] = torch.mm(b_grad[11-i],w_list[11 - i].T)\n",
    "        b_grad[10 - i][h_list[10 - i]<=0] = 0\n",
    "        w_grad[10 - i] = torch.mm(h_list[9-i].T,b_grad[10-i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ccdc3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('my_grad_b.txt','w')\n",
    "for i in range(len(b_grad)):\n",
    "    for j in range(len(b_grad[i])):\n",
    "        f.write(str(b_grad[i][j]))\n",
    "        f.write('\\t')\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "01cb78b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open('my_grad_w.txt','w')\n",
    "for i in range(len(w_grad)):\n",
    "        f.write(str(w_grad[i]))\n",
    "        f.write('\\t')\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770aa8b3",
   "metadata": {},
   "source": [
    "### Torch Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9d48d979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# weight & Bias\n",
    "w1_auto = torch.tensor(w1.detach().cpu().numpy(),requires_grad=True)  #1\n",
    "b1_auto = torch.tensor(b1.detach().cpu().numpy(),requires_grad=True) \n",
    "w_auto_list=[w1_auto]\n",
    "b_auto_list=[b1_auto]\n",
    "for i in range(9):\n",
    "    w_auto_list.append(torch.tensor(w_list[i+1].detach().cpu().numpy(),requires_grad=True)) #1+9\n",
    "    b_auto_list.append(torch.tensor(b_list[i+1].detach().cpu().numpy(),requires_grad=True))\n",
    "w_auto_11 = torch.tensor(w11.detach().cpu().numpy(),requires_grad=True)\n",
    "b_auto_11 = torch.tensor(b11.detach().cpu().numpy(),requires_grad=True) \n",
    "w_auto_list.append(w_auto_11)\n",
    "b_auto_list.append(b_auto_11)\n",
    "\n",
    "#Auto Forward-propagation\n",
    "h_auto_list=[F.relu(torch.matmul(x, w_auto_list[0])+b_auto_list[0])]#1 0\n",
    "\n",
    "for i in range(9):\n",
    "    h_auto_list.append(F.relu(torch.matmul(h_auto_list[i], w_auto_list[i+1])+b_auto_list[i+1])) #9 0-8\n",
    "y_auto_pred = F.relu(torch.matmul(h_auto_list[9], w_auto_11)+b_auto_11).sum()\n",
    "\n",
    "#Loss Function\n",
    "loss = (y_auto_pred-y).pow(2).sum()\n",
    "#back-propagation\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e176f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('torch_grad_b.txt','w')\n",
    "for i in range(len(b_auto_list)):\n",
    "    f.write(str(b_auto_list[i].grad))\n",
    "    f.write('\\t')\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8b13b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('torch_grad_w.txt','w')\n",
    "for i in range(len(w_auto_list)):\n",
    "    f.write(str(w_auto_list[i].grad))\n",
    "    f.write('\\t')\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff369c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
